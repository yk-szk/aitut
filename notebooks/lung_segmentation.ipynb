{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYqrqzgd-t3j"
   },
   "source": [
    "# 肺野セグメンテーション\n",
    "\n",
    "## 前準備\n",
    "### 主要パッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WSFQMTTE-t3k"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from logging import basicConfig, getLogger, INFO\n",
    "basicConfig(level=INFO, format='%(asctime)s %(levelname)s :%(message)s')\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moY2hgoO-t3o"
   },
   "source": [
    "### データディレクトリの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTkR-zBp-t3p"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = pathlib.Path('Data/Images/chest_xray')\n",
    "IMAGE_DIR = 'regular'\n",
    "LABEL_DIR = 'lung'\n",
    "CLASS_LABELS = ('lung')\n",
    "IMAGE_EXT = '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pk8Hxqh_-t3s"
   },
   "source": [
    "### 画像ファイルを基にpd.DataFrameを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "B0uZrUGE-t3s",
    "outputId": "c62f581b-e349-446b-95c2-d9a0503b08eb"
   },
   "outputs": [],
   "source": [
    "def create_dataset_df(data_root, image_dir, label_dir, image_ext):\n",
    "    dfs = []\n",
    "    root = pathlib.Path(data_root)\n",
    "    image_filenames = (root / pathlib.Path(image_dir)).glob('*' + image_ext)\n",
    "    df = pd.DataFrame(image_filenames, columns=['image_path'])\n",
    "    df['label_path'] = df['image_path'].map(\n",
    "        lambda p: root / pathlib.Path(label_dir) / p.name)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_dataset = create_dataset_df(DATA_ROOT, IMAGE_DIR, LABEL_DIR, IMAGE_EXT)\n",
    "display(df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiL6rk0q-t3x"
   },
   "source": [
    "### 画像を表示\n",
    "入力画像を背景にセグメンテーションを重畳表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "TrTnSTfN-t3y",
    "outputId": "3cdee2b5-203f-46de-f788-31bcaf617d1d"
   },
   "outputs": [],
   "source": [
    "OVERLAY_ALPHA = 0.5\n",
    "cmap = np.array([[0, 0, 0, 0], [255, 0, 0,\n",
    "                                255 * OVERLAY_ALPHA]]).astype(np.uint8)\n",
    "\n",
    "N_SAMPLES = 5\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, sample in enumerate(df_dataset.sample(n=N_SAMPLES).itertuples()):\n",
    "    image = Image.open(sample.image_path).convert('RGBA')\n",
    "    label = np.array(Image.open(sample.label_path).convert('L'))\n",
    "    label = (label > 0).astype(np.uint8)\n",
    "    label = Image.fromarray(cmap[label])\n",
    "    plt.subplot(1, N_SAMPLES, i + 1)\n",
    "    plt.imshow(Image.alpha_composite(image, label))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "回転、左右反転等をランダムに適用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "IMG_SHAPE = (3, 256, 256)\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize(IMG_SHAPE[1:])\n",
    "    return np.atleast_3d(img)\n",
    "\n",
    "\n",
    "def load_img2img_dataset(df, load_img):\n",
    "    data = np.stack(\n",
    "        [load_img(filepath) for filepath in tqdm.tqdm(df['image_path'])])\n",
    "    labels = np.stack([\n",
    "        load_img(filepath)[..., :1] for filepath in tqdm.tqdm(df['label_path'])\n",
    "    ])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "0RxzGKGb-t4G",
    "outputId": "f60ff398-9fff-4267-99f0-3f19e1aa78e0"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from tut_utils import AugmentedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "album_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=.25),\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=.1, rotate_limit=5, p=.8)\n",
    "])\n",
    "\n",
    "\n",
    "def random_transform(x, y):\n",
    "    x = (x / 255).astype(np.float32)\n",
    "    y = (y / 255).astype(np.float32)\n",
    "    tfed = album_transform(image=x, mask=y)\n",
    "    x, y = tfed['image'], tfed['mask']\n",
    "    x, y = x.transpose(2, 0, 1), y.transpose(2, 0, 1)  # to channels first\n",
    "    return x.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "\n",
    "N_TEST = 3\n",
    "\n",
    "\n",
    "def test_augmentation(df_dataset):\n",
    "    df_train = df_dataset.iloc[:N_TEST]\n",
    "    train_data, train_labels = load_img2img_dataset(df_train, load_img)\n",
    "    dataset = AugmentedDataset(train_data, train_labels, random_transform)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    for i, data in enumerate(loader):\n",
    "        plt.figure(figsize=(4, 1.5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(data[0].squeeze().numpy(), cmap='gray')\n",
    "        plt.title('input image')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(data[1].squeeze().numpy(), cmap='gray')\n",
    "        plt.title('label image')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "test_augmentation(df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウト\n",
    "学習に時間がかかるため、今回は交差検証は行わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0rthjmd-t31"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "N_SPLITS = 5\n",
    "kfold = KFold(n_splits=N_SPLITS, shuffle=True)\n",
    "train_index, test_index = next(kfold.split(df_dataset['image_path']))\n",
    "\n",
    "df_train = df_dataset.iloc[train_index]\n",
    "df_test = df_dataset.iloc[test_index]\n",
    "print('training:', len(df_train), 'test:', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SIdvrDp-t37"
   },
   "source": [
    "## モデル作成\n",
    "[U-Net](https://arxiv.org/abs/1505.04597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHS = 1\n",
    "OUT_CHS = 1\n",
    "UNET_DEPTH = 4\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_chs,\n",
    "                      out_chs,\n",
    "                      kernel_size=kernel_size,\n",
    "                      padding=padding), nn.BatchNorm2d(out_chs),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_chs: int, mid_chs: int, out_chs: int,\n",
    "                 kernel_size: int, padding: int):\n",
    "        super().__init__()\n",
    "        self.out_chs = out_chs\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBNReLU(in_chs, mid_chs, kernel_size, padding),\n",
    "            ConvBNReLU(mid_chs, out_chs, kernel_size, padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_chs,\n",
    "                 out_chs,\n",
    "                 kernel_size,\n",
    "                 padding,\n",
    "                 scale_factor: int,\n",
    "                 apply_dropout=False):\n",
    "        super().__init__()\n",
    "        self.out_chs = out_chs\n",
    "        mid_chs = (in_chs + out_chs) // 2\n",
    "        self.up = nn.Upsample(scale_factor=scale_factor,\n",
    "                              mode='bilinear',\n",
    "                              align_corners=True)\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBNReLU(in_chs, mid_chs, kernel_size, padding),\n",
    "            ConvBNReLU(mid_chs, out_chs, kernel_size, padding),\n",
    "        )\n",
    "\n",
    "        if apply_dropout:\n",
    "            self.dropout = nn.Dropout(.25)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        cat = torch.cat([self.up(x1), x2], dim=1)\n",
    "        x = self.block(cat)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_chs,\n",
    "                 out_chs,\n",
    "                 depth,\n",
    "                 ini_chs=8,\n",
    "                 kernel_size=3,\n",
    "                 padding=1,\n",
    "                 scale_factor=2):\n",
    "        '''\n",
    "        Args:\n",
    "            depth (int): UNets depth i.e # of downsampling layers\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.encs = nn.ModuleList()\n",
    "        self.decs = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        chs = ini_chs\n",
    "        for i in range(depth):\n",
    "            enc = Encoder(in_chs if i == 0 else chs, chs, chs * 2, kernel_size,\n",
    "                          padding)\n",
    "            self.encs.append(enc)\n",
    "            chs = chs * 2\n",
    "            if i < (depth - 1):\n",
    "                self.pools.append(nn.MaxPool2d(scale_factor))\n",
    "\n",
    "        for i in range(depth - 1):\n",
    "            enc_below = self.encs[-i - 1]\n",
    "            enc_left = self.encs[-i - 2]\n",
    "            dec = Decoder(enc_left.out_chs + enc_below.out_chs,\n",
    "                          enc_left.out_chs,\n",
    "                          kernel_size,\n",
    "                          padding,\n",
    "                          scale_factor,\n",
    "                          apply_dropout=i < depth // 2)\n",
    "            self.decs.append(dec)\n",
    "\n",
    "        self.output_layer = nn.Conv2d(self.decs[-1].out_chs,\n",
    "                                      out_chs,\n",
    "                                      kernel_size=1,\n",
    "                                      padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for i in range(self.depth):\n",
    "            x = self.encs[i](x)\n",
    "            if i < (self.depth - 1):\n",
    "                skips.append(x)\n",
    "                x = self.pools[i](x)\n",
    "\n",
    "        for i in range(self.depth - 1):\n",
    "            x = self.decs[i](x, skips[-(i + 1)])\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(UNet(IN_CHS, OUT_CHS, UNET_DEPTH), (1, 512, 512),\n",
    "        verbose=0,\n",
    "        device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワーク構造の可視化\n",
    "スキップコネクションを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "dummy_x = torch.zeros((1, 1, 512, 512), dtype=torch.float, requires_grad=False)\n",
    "dummy_y = UNet(IN_CHS, OUT_CHS, UNET_DEPTH)(dummy_x)\n",
    "dot = torchviz.make_dot(dummy_y)\n",
    "dot.format = 'svg'\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5m1qqUxc-t4F"
   },
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "### pytorch-lightining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "NUM_WORKERS = 0 if os.name == 'nt' else 2\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "class LitUNet(pl.LightningModule):\n",
    "    def __init__(self, in_chs, out_chs, depth):\n",
    "        super().__init__()\n",
    "        self.model = UNet(in_chs, out_chs, depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "EPOCHS = 32\n",
    "PATIENCE = 4\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "model = LitUNet(IN_CHS, OUT_CHS, UNET_DEPTH)\n",
    "\n",
    "train_data, train_labels = load_img2img_dataset(df_train, load_img)\n",
    "dataset = AugmentedDataset(train_data, train_labels, random_transform)\n",
    "trainloader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=NUM_WORKERS)\n",
    "early_stop_callback = EarlyStopping(monitor='train_loss',\n",
    "                                    patience=PATIENCE,\n",
    "                                    verbose=False,\n",
    "                                    mode='min')\n",
    "csv_logger = CSVLogger('train_logs', name='lung_segmentation')\n",
    "trainer = pl.Trainer(gpus=1 if torch.cuda.is_available() else 0,\n",
    "                     max_epochs=EPOCHS,\n",
    "                     logger=csv_logger,\n",
    "                     log_every_n_steps=len(trainloader),\n",
    "                     callbacks=[early_stop_callback])\n",
    "\n",
    "trainer.fit(model, trainloader)\n",
    "logger.info('Finish training')\n",
    "df_logs = pd.read_csv(csv_logger.experiment.metrics_file_path)\n",
    "df_logs.plot(y='train_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "467GUQkS-t4O"
   },
   "source": [
    "## 評価\n",
    "Dice similarity coefficient(F1 score)とJaccard Index(IoU)を評価指標とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXsNeBGr-t4O"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "label_cmap = np.array([[0, 0, 0], [255, 0, 0], [0, 255, 0], [255, 255, 0]])\n",
    "\n",
    "test_data, test_labels = load_img2img_dataset(df_test, load_img)\n",
    "test_data = (test_data / 255).astype(np.float32)\n",
    "test_labels = (test_labels > 0).astype(np.uint8)\n",
    "\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "scores = []\n",
    "for i, (data, label) in enumerate(zip(test_data, test_labels)):\n",
    "    data = data.transpose((2, 0, 1))[np.newaxis]\n",
    "    label = label.astype(np.uint8).squeeze()\n",
    "    with torch.no_grad():\n",
    "        pred = torch.sigmoid(model(torch.FloatTensor(data)))\n",
    "        pred = pred.cpu().numpy().squeeze()\n",
    "    pred_bin = (pred > .5).astype(np.uint8)\n",
    "    scores.append((metrics.f1_score(label.ravel(), pred_bin.ravel()),\n",
    "                   metrics.jaccard_score(label.ravel(), pred_bin.ravel())))\n",
    "    if i < N_SAMPLES:\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(data.squeeze(), cmap='gray')\n",
    "        plt.title('input')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(pred, cmap='jet')\n",
    "        plt.title('result')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(label_cmap[[0, 1]][pred_bin.astype(np.uint8).squeeze()])\n",
    "        plt.title('result label')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(label_cmap[[0, 2]][label.astype(np.uint8)])\n",
    "        plt.title('true label')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(label_cmap[pred_bin + label * 2])\n",
    "        plt.title('comparison')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmPLf7yB-t4S"
   },
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(scores,\n",
    "                        columns=['dice coefficient', 'jaccard index'],\n",
    "                        index=test_index)\n",
    "display(df_score.head())\n",
    "display(\n",
    "    pd.DataFrame({\n",
    "        'median': df_score.median(),\n",
    "        'mean': df_score.mean(),\n",
    "        'std': df_score.std(),\n",
    "        'min': df_score.min(),\n",
    "        'max': df_score.max(),\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分布の確認\n",
    "Dice similarity coefficientの分布を表示する。\n",
    "\n",
    "#### ヒストグラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(x=df_score['dice coefficient'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='dice coefficient', data=df_score)\n",
    "sns.swarmplot(x='dice coefficient', data=df_score, color='.2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Letter value plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(x='dice coefficient', data=df_score)\n",
    "sns.swarmplot(x='dice coefficient',\n",
    "              data=df_score,\n",
    "              color='white',\n",
    "              edgecolor='black',\n",
    "              linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='dice coefficient', data=df_score, inner=None)\n",
    "sns.swarmplot(x='dice coefficient',\n",
    "              data=df_score,\n",
    "              color='white',\n",
    "              edgecolor='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lung_segmentation_tfdata.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "359.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
