{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pixとU-Netの比較\n",
    "2つのモデルが出力する画像を比較する。\n",
    "\n",
    "## 前準備\n",
    "### 主要パッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from logging import basicConfig, getLogger, INFO\n",
    "basicConfig(level=INFO, format='%(asctime)s %(levelname)s :%(message)s')\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データディレクトリの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = pathlib.Path('Data/Images/chest_xray')\n",
    "INPUT_IMAGE_DIR = 'bone_enhancement'\n",
    "TRUTH_IMAGE_DIR = 'bone_suppression'\n",
    "CLASS_LABELS = ('lung')\n",
    "IMAGE_EXT = '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像ファイルを基にpd.DataFrameを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_df(data_root, input_dir, truth_dir, image_ext):\n",
    "    dfs = []\n",
    "    root = pathlib.Path(data_root)\n",
    "    image_filenames = (root / pathlib.Path(input_dir)).glob('*' + image_ext)\n",
    "    df = pd.DataFrame(image_filenames, columns=['input_path'])\n",
    "    df['truth_path'] = df['input_path'].map(\n",
    "        lambda p: root / pathlib.Path(truth_dir) / p.name)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_dataset = create_dataset_df(DATA_ROOT, INPUT_IMAGE_DIR, TRUTH_IMAGE_DIR,\n",
    "                               IMAGE_EXT)\n",
    "display(df_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウトされたデータの取り出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "N_SPLITS = 5\n",
    "SEED = 0\n",
    "kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "train_index, test_index = next(kfold.split(df_dataset['input_path']))\n",
    "\n",
    "df_train = df_dataset.iloc[train_index]\n",
    "df_test = df_dataset.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "import tut_utils\n",
    "INPUT_SHAPE = [1, 256, 256]\n",
    "IMG_SHAPE = INPUT_SHAPE\n",
    "N_COMPARE = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize(IMG_SHAPE[1:])\n",
    "    return np.atleast_3d(img)\n",
    "\n",
    "\n",
    "load_img2img_dataset = functools.partial(tut_utils.load_img2img_dataset,\n",
    "                                         input_column='input_path',\n",
    "                                         target_column='truth_path')\n",
    "test_data, test_labels = load_img2img_dataset(df_test[:N_COMPARE], load_img)\n",
    "test_data = torch.from_numpy(\n",
    "    (test_data.transpose(0, 3, 1, 2) / 255).astype(np.float32))\n",
    "test_data = test_data.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像変換\n",
    "### U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tut_models import UNet\n",
    "UNET_DEPTH = 6\n",
    "IN_CHS = 1\n",
    "OUT_CHS = 1\n",
    "INI_CHS = 16\n",
    "\n",
    "net = UNet(IN_CHS, OUT_CHS, UNET_DEPTH)\n",
    "net.load_state_dict(torch.load('unet_generator.ckpt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    unet_prediction = net(test_data).cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(IN_CHS, OUT_CHS, UNET_DEPTH)\n",
    "net.load_state_dict(torch.load('pix2pix_generator.ckpt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    pix2pix_prediction = net(test_data).cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_show(image):\n",
    "    margin = 32\n",
    "    plt.imshow(image[margin:-margin * 2, margin:-margin], cmap='gray')\n",
    "\n",
    "\n",
    "for data, target, pix2pix, unet in zip(test_data.cpu().numpy(), test_labels,\n",
    "                                       pix2pix_prediction, unet_prediction):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    crop_and_show(data.squeeze())\n",
    "    plt.title('Input')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 2)\n",
    "    crop_and_show(pix2pix.squeeze())\n",
    "    plt.title('pix2pix')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    crop_and_show(unet.squeeze())\n",
    "    plt.title('U-Net')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    crop_and_show(target.squeeze())\n",
    "    plt.title('Ground truth')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
