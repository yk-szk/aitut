{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bone suppression(pix2pix)\n",
    "\n",
    "参考：[Pix2Pix  |  TensorFlow Core](https://www.tensorflow.org/tutorials/generative/pix2pix#training)\n",
    "\n",
    "## 前準備\n",
    "### 主要パッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from logging import basicConfig, getLogger, INFO\n",
    "basicConfig(level=INFO, format='%(asctime)s %(levelname)s :%(message)s')\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データディレクトリの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = pathlib.Path('Data/Images/chest_xray')\n",
    "INPUT_IMAGE_DIR = 'bone_enhancement'\n",
    "TRUTH_IMAGE_DIR = 'bone_suppression'\n",
    "CLASS_LABELS = ('lung')\n",
    "IMAGE_EXT = '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像ファイルを基にpd.DataFrameを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_df(data_root, input_dir, truth_dir, image_ext):\n",
    "    dfs = []\n",
    "    root = pathlib.Path(data_root)\n",
    "    image_filenames = (root / pathlib.Path(input_dir)).glob('*' + image_ext)\n",
    "    df = pd.DataFrame(image_filenames, columns=['input_path'])\n",
    "    df['truth_path'] = df['input_path'].map(\n",
    "        lambda p: root / pathlib.Path(truth_dir) / p.name)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_dataset = create_dataset_df(DATA_ROOT, INPUT_IMAGE_DIR, TRUTH_IMAGE_DIR,\n",
    "                               IMAGE_EXT)\n",
    "display(df_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 3\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, sample in enumerate(df_dataset.sample(n=N_SAMPLES).itertuples()):\n",
    "    image = Image.open(sample.input_path)\n",
    "    truth = Image.open(sample.truth_path)\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(truth, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成\n",
    "\n",
    "### Generator model\n",
    "構造はhttps://www.tensorflow.org/tutorials/generative/pix2pix のgeneratorを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters,\n",
    "                               size,\n",
    "                               strides=2,\n",
    "                               padding='same',\n",
    "                               kernel_initializer=initializer,\n",
    "                               use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters,\n",
    "                                        size,\n",
    "                                        strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [256, 256, 1]\n",
    "OUTPUT_CHANNELS = 1\n",
    "OUTPUT_SHAPE = INPUT_SHAPE[:2] + [OUTPUT_CHANNELS]\n",
    "\n",
    "\n",
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),  # (bs, 128, 128, 64)\n",
    "        downsample(128, 4),  # (bs, 64, 64, 128)\n",
    "        downsample(256, 4),  # (bs, 32, 32, 256)\n",
    "        downsample(512, 4),  # (bs, 16, 16, 512)\n",
    "        downsample(512, 4),  # (bs, 8, 8, 512)\n",
    "        downsample(512, 4),  # (bs, 4, 4, 512)\n",
    "        downsample(512, 4),  # (bs, 2, 2, 512)\n",
    "        downsample(512, 4),  # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4),  # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4),  # (bs, 32, 32, 512)\n",
    "        upsample(128, 4),  # (bs, 64, 64, 256)\n",
    "        upsample(64, 4),  # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        OUTPUT_CHANNELS,\n",
    "        4,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer=initializer,\n",
    "        activation='linear')  # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output),\n",
    "                           disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=OUTPUT_SHAPE, name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=OUTPUT_SHAPE, name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n",
    "    down4 = downsample(256, 4)(down3)  # (bs, 32, 32, 256)\n",
    "\n",
    "#     zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
    "    zero_pad1 = down4\n",
    "    conv = tf.keras.layers.Conv2D(512,\n",
    "                                  4,\n",
    "                                  strides=1,\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  use_bias=False)(\n",
    "                                      zero_pad1)  # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "    \n",
    "    leaky_relu = tf.keras.layers.Conv2D(128,4,strides=1)(leaky_relu)\n",
    "    leaky_relu = tf.keras.layers.BatchNormalization()(leaky_relu)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(leaky_relu)\n",
    "\n",
    "#     zero_pad2 = tf.keras.layers.ZeroPadding2D()(\n",
    "#         leaky_relu)  # (bs, 33, 33, 512)\n",
    "    zero_pad2 = leaky_relu\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1,\n",
    "                                  4,\n",
    "                                  strides=1,\n",
    "                                  kernel_initializer=initializer)(\n",
    "                                      zero_pad2)  # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output),\n",
    "                                 disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "checkpoint_dir = pathlib.Path('pi2pix_training_checkpoints')\n",
    "checkpoint_prefix = checkpoint_dir / 'ckpt'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "### ホールドアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "N_SPLITS = 5\n",
    "SEED = 0\n",
    "kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "train_index, test_index = next(kfold.split(df_dataset['input_path']))\n",
    "\n",
    "df_train = df_dataset.iloc[train_index]\n",
    "df_test = df_dataset.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "IMG_SHAPE = INPUT_SHAPE\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    return np.atleast_3d(\n",
    "        tf.keras.preprocessing.image.load_img(filepath,\n",
    "                                              color_mode='grayscale',\n",
    "                                              target_size=IMG_SHAPE))\n",
    "\n",
    "\n",
    "def load_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        np.stack([\n",
    "            load_img(filepath) for filepath in tqdm.tqdm(df['input_path'])\n",
    "        ]),\n",
    "        np.stack([\n",
    "            load_img(filepath) for filepath in tqdm.tqdm(df['truth_path'])\n",
    "        ]),\n",
    "    ))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_dataset(df_train)\n",
    "test_dataset = load_dataset(df_test)\n",
    "print(train_dataset.element_spec, test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def convert(image, truth):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    truth = tf.image.convert_image_dtype(truth, tf.float32)\n",
    "    return image, truth\n",
    "\n",
    "\n",
    "MAX_ANGLE_DEG = 10\n",
    "MAX_ANGLE_RAD = np.deg2rad(MAX_ANGLE_DEG)\n",
    "FLIP_RATE = .5\n",
    "BRIGHTNESS_RANGE = .2\n",
    "\n",
    "\n",
    "def augment(image, truth):\n",
    "    image, truth = convert(image, truth)\n",
    "    # rotate\n",
    "    angle = tf.random.uniform((), minval=-MAX_ANGLE_RAD, maxval=MAX_ANGLE_RAD)\n",
    "    image = tfa.image.rotate(image, angle, interpolation='BILINEAR')\n",
    "    truth = tfa.image.rotate(truth, angle, interpolation='BILINEAR')\n",
    "\n",
    "    # flip\n",
    "    if tf.random.uniform(()) < FLIP_RATE:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        truth = tf.image.flip_left_right(truth)\n",
    "\n",
    "    # brightness\n",
    "    brightness_offset = tf.random.uniform((),\n",
    "                                          minval=-BRIGHTNESS_RANGE,\n",
    "                                          maxval=BRIGHTNESS_RANGE)\n",
    "    image = image + brightness_offset\n",
    "    truth = truth + brightness_offset\n",
    "\n",
    "    return image, truth\n",
    "\n",
    "\n",
    "for d in train_dataset.map(augment):\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(d[0][..., 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(d[1][..., 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output],\n",
    "                                              training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
    "            disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                            generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(\n",
    "        disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "#     with summary_writer.as_default():\n",
    "#         tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "#         tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "#         tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "#         tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "\n",
    "    return (gen_total_loss, gen_gan_loss, gen_l1_loss), disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 512\n",
    "BATCH_SIZE = 8\n",
    "DISPLAY_FREQ = EPOCHS // 8\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_dataset.shuffle(BATCH_SIZE * 16).map(\n",
    "    augment, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input[np.newaxis], training=True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input, tar, prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i][..., 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit(train_ds, epochs, test_ds):\n",
    "    pbar_total = len(train_index)\n",
    "    all_logs = []\n",
    "    with tqdm.tqdm(total=pbar_total, unit='batch') as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            pbar.reset(total=pbar_total)\n",
    "            logs = []\n",
    "\n",
    "            if epoch % DISPLAY_FREQ == 0:\n",
    "                for example_input, example_target in test_ds.map(convert).take(\n",
    "                        1):\n",
    "                    logger.info('generate_images')\n",
    "                    generate_images(generator, example_input, example_target)\n",
    "\n",
    "            for n, (input_image, target) in train_ds.enumerate():\n",
    "                gen_loss, disc_loss = train_step(input_image, target, epoch)\n",
    "                pbar.update(BATCH_SIZE)\n",
    "                cur_logs = {\n",
    "                    'G_L': gen_loss[0].numpy(),\n",
    "                    'G_L_gan': gen_loss[1].numpy(),\n",
    "                    'G_L_l1': gen_loss[2].numpy(),\n",
    "                    'D_L': disc_loss.numpy()\n",
    "                }\n",
    "                pbar.set_postfix(cur_logs)\n",
    "                logs.append(cur_logs)\n",
    "\n",
    "            summary = pd.DataFrame(logs).mean().to_dict()\n",
    "            pbar.set_description('{}/{} [{}]'.format(\n",
    "                epoch + 1, epochs, ','.join(\n",
    "                    ['{}={:.02g}'.format(k, v) for k, v in summary.items()])))\n",
    "            all_logs.append(summary)\n",
    "\n",
    "        return all_logs\n",
    "\n",
    "# saving (checkpoint) the model every 20 epochs\n",
    "#         if (epoch + 1) % 20 == 0:\n",
    "#             checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "#         print('Time taken for epoch {} is {} sec\\n'.format(\n",
    "#             epoch + 1,\n",
    "#             time.time() - start))\n",
    "#     checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "logger.info('start of training')\n",
    "logs = fit(train_ds, EPOCHS, test_dataset)\n",
    "logger.info('end of training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logs).plot(title='Training history', figsize=(5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価\n",
    "準備中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def show_images_in_a_row(images, titles, figsize=(15, 5)):\n",
    "    assert len(images) == len(titles), 'Invalid size of arguments'\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, (image, title) in enumerate(zip(images, titles), 1):\n",
    "        plt.subplot(1, len(images), i)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "scores = []\n",
    "for i, batch in enumerate(test_dataset.map(convert).batch(1)):\n",
    "    pred = generator(batch[0])\n",
    "    \n",
    "    pred = pred[0,...,0]\n",
    "    image = batch[0][0,...,0]\n",
    "    truth = batch[1][0,...,0]\n",
    "    if i < 2:\n",
    "        show_images_in_a_row(*zip((image, 'input'), (pred, 'output'), (\n",
    "            truth, 'truth'), (image - pred, 'input-output'), (\n",
    "                image - truth, 'input-truth'), (pred - truth, 'output-truth')))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('pix2pix_generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "278.667px",
    "left": "2214.33px",
    "right": "20px",
    "top": "120px",
    "width": "325.667px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
